output_dir: ./temp

hydra:
  run:
    dir: ${output_dir}

version: 1.1.0
defaults:
  - _self_

logging:
  file: "run_hydra.log"

documents:
  paths:
    - "/Users/omidmaghsoudi/github/LLM_RAGs/src/omid_llm/dataset/ai_adoption_framework_whitepaper.pdf"

text_splitter:
  separator: "\n"
  chunk_size: 2000
  chunk_overlap: 200

embeddings: null

retriever:
  k: 4

llm:
  model: "llama3"
  temperature: 0.0

prompt:
  system: >
    You are a helpful assistant. Use the provided context to answer the question.
    If the answer is not contained in the context, say you do not know.

questions:
  - "Can you please summarize the document"

